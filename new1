import cv2
import numpy as np
import pyfirmata
from ultralytics import YOLO

# Connect to Arduino
board = pyfirmata.Arduino('COM5')  # Change port as necessary
servo_pin_1 = 9
servo_pin_2 = 10
servo_pin_3 = 11

it = pyfirmata.util.Iterator(board)
it.start()

board.digital[servo_pin_1].mode = pyfirmata.SERVO
board.digital[servo_pin_2].mode = pyfirmata.SERVO
board.digital[servo_pin_3].mode = pyfirmata.SERVO


# Function to move servo to a specific angle
def move_servo(pin, angle):
    # Ensure angle is within the valid range
    angle = max(min(angle, 180), 0)  # Clamp angle between 0 and 180 degrees

    # Convert angle to PWM value (0-180 degrees map to 0-180 PWM)
    pwm_value = int(angle * (2000 / 180))

    # Write PWM value to the servo pin
    board.digital[pin].write(pwm_value)


# Model
model = YOLO("yolo-Weights/yolov8n.pt")  # Adjust path if your model is in a different location

# Object classes
classNames = ["person", "bicycle", "car", "motorbike", "aeroplane", "bus", "train", "truck", "boat",
              "traffic light", "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat",
              "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack", "umbrella",
              "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sports ball", "kite", "baseball bat",
              "baseball glove", "skateboard", "surfboard", "tennis racket", "bottle", "wine glass", "cup",
              "fork", "knife", "spoon", "bowl", "banana", "apple", "sandwich", "orange", "broccoli",
              "carrot", "hot dog", "pizza", "donut", "cake", "chair", "sofa", "pottedplant", "bed",
              "diningtable", "toilet", "tvmonitor", "laptop", "mouse", "remote", "keyboard", "cell phone",
              "microwave", "oven", "toaster", "sink", "refrigerator", "book", "clock", "vase", "scissors",
              "teddy bear", "hair drier", "toothbrush"
              ]

# Known length in pixels and centimeters
known_length_pixels = 475
known_length_cm = 17

# Calculate conversion factor
conversion_factor = known_length_cm / known_length_pixels


# Function to calculate inverse kinematics
def calculate_inverse_kinematics(midpoint_x_cm, midpoint_y_cm, midpoint_z_cm):
    # Length of the links
    a_1 = 20
    a_2 = 20
    a_3 = 10

    # Calculate servo angles
    theta_1 = np.degrees(np.arctan2(midpoint_y_cm, midpoint_x_cm))
    r_1 = np.sqrt(midpoint_x_cm ** 2 + midpoint_y_cm ** 2)
    r_2 = midpoint_z_cm - a_1
    phi_2 = np.arctan2(r_2, r_1)
    numerator = a_3 ** 2 - a_2 ** 2 - r_1 ** 2 - r_2 ** 2
    denominator = -2 * a_2 * np.sqrt(r_1 ** 2 + r_2 ** 2)
    phi_1 = np.arccos(np.clip(numerator / denominator, -1, 1))
    theta_2 = np.degrees(phi_1 - phi_2)
    numerator = r_1 ** 2 + r_2 ** 2 - a_2 ** 2 - a_3 ** 2
    denominator = -2 * a_2 * a_3
    phi_3 = np.arccos(np.clip(numerator / denominator, -1, 1))
    theta_3 = np.degrees(np.pi - phi_3)

    return theta_1, theta_2, theta_3


# Start webcam
cap = cv2.VideoCapture(0)
cap.set(3, 640)  # Adjust resolution if needed
cap.set(4, 480)  # Adjust resolution if needed

while True:
    success, img = cap.read()
    img = cv2.flip(img, 1)  # Flips the frame horizontally

    results = model(img, stream=True)  # Perform object detection

    # Frame dimensions
    height, width, _ = img.shape

    # Calculate new origin (midpoint of the bottom line)
    origin_x = width // 2
    origin_y = height  # Bottom of the frame

    # Flag to track if a scissor is detected
    scissor_detected = False

    for r in results:
        boxes = r.boxes

        for box in boxes:
            if classNames[int(box.cls[0])] == "scissors" and not scissor_detected:
                # Set flag to indicate scissor detection
                scissor_detected = True

                # Bounding box (coordinates unchanged)
                x1, y1, x2, y2 = box.xyxy[0]
                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)

                # Midpoint of the bounding box (unchanged)
                midpoint_x = (x1 + x2) // 2
                midpoint_y = (y1 + y2) // 2

                # Convert midpoint coordinates from pixels to centimeters
                midpoint_x_cm = (origin_y - midpoint_y) * conversion_factor
                midpoint_y_cm = -(midpoint_x - origin_x) * conversion_factor  # Invert the sign of y-coordinate
                midpoint_z_cm = 5

                cv2.line(img, (midpoint_x, midpoint_y), (origin_x, origin_y), (255, 255, 0), 2)

                # Calculate inverse kinematics
                theta_1, theta_2, theta_3 = calculate_inverse_kinematics(midpoint_x_cm, midpoint_y_cm, midpoint_z_cm)

                initial_angle = 90
                target_angle = int(initial_angle + theta_1)


                initial_angle_1 = 50
                target_angle_1 = int(initial_angle_1 + theta_2)

                initial_angle_2 = 45
                target_angle_2 = int(initial_angle_2 + theta_3)







                # Move servos to calculated angles
                move_servo(servo_pin_1, int(target_angle))
                move_servo(servo_pin_2, int(target_angle_1))
                move_servo(servo_pin_3, int(target_angle_2))

                # Print calculated joint angles
                print("Joint angles:", int(theta_1), int(theta_2), int(theta_3))
                print("servo angles:", target_angle, target_angle_1, target_angle_2)

                # Other visualization and printing code remains the same as in your original code

                # Break out of the inner loop to stop processing further detections
                break

    # Draw axes (adjusted for the new origin)
    cv2.line(img, (origin_x, 0), (origin_x, height), (0, 255, 0), 2)  # Y-axis (Green)
    cv2.line(img, (0, origin_y), (width, origin_y), (0, 0, 255), 2)  # X-axis (Red)

    # Label axes
    cv2.putText(img, 'X', (origin_x + 10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
    cv2.putText(img, 'Y', (10, origin_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Display the image
    cv2.imshow('Webcam', img)

    # Exit condition
    if cv2.waitKey(1) == ord('q'):
        break

# Cleanup
cap.release()
cv2.destroyAllWindows()
board.exit()
