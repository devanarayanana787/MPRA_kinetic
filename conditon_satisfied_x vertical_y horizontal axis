import cv2
import math
from ultralytics import YOLO

# Start webcam
cap = cv2.VideoCapture(0)
cap.set(3, 640)  # Adjust resolution if needed
cap.set(4, 480)  # Adjust resolution if needed

# Model
model = YOLO("yolo-Weights/yolov8n.pt")  # Adjust path if your model is in a different location

# Object classes
classNames = ["person", "bicycle", "car", "motorbike", "aeroplane", "bus", "train", "truck", "boat",
              "traffic light", "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat",
              "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack", "umbrella",
              "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sports ball", "kite", "baseball bat",
              "baseball glove", "skateboard", "surfboard", "tennis racket", "bottle", "wine glass", "cup",
              "fork", "knife", "spoon", "bowl", "banana", "apple", "sandwich", "orange", "broccoli",
              "carrot", "hot dog", "pizza", "donut", "cake", "chair", "sofa", "pottedplant", "bed",
              "diningtable", "toilet", "tvmonitor", "laptop", "mouse", "remote", "keyboard", "cell phone",
              "microwave", "oven", "toaster", "sink", "refrigerator", "book", "clock", "vase", "scissors",
              "teddy bear", "hair drier", "toothbrush"
              ]

# Known length in pixels and centimeters
known_length_pixels = 475
known_length_cm = 17

# Calculate conversion factor
conversion_factor = known_length_cm / known_length_pixels

while True:
    success, img = cap.read()
    img = cv2.flip(img, 1)  # Flips the frame horizontally

    results = model(img, stream=True)  # Perform object detection

    # Frame dimensions
    height, width, _ = img.shape

    # Calculate new origin (midpoint of the bottom line)
    origin_x = width // 2
    origin_y = height  # Bottom of the frame

    # Coordinates, filtering, and visualization
    for r in results:
        boxes = r.boxes

        for box in boxes:
            # Bounding box (coordinates unchanged)
            x1, y1, x2, y2 = box.xyxy[0]
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)

            # Filter for 'scissors' class
            if classNames[int(box.cls[0])] == "scissors":
                cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)

                # Confidence
                confidence = math.ceil((box.conf[0] * 100)) / 100
                print("Confidence --->", confidence)

                # Class name
                cls = int(box.cls[0])
                print("Class name -->", classNames[cls])

                # Object details
                org = [x1, y1]
                font = cv2.FONT_HERSHEY_SIMPLEX
                fontScale = 1
                color = (255, 0, 0)
                thickness = 2
                cv2.putText(img, classNames[cls], org, font, fontScale, color, thickness)

                # Midpoint of the bounding box (unchanged)
                midpoint_x = (x1 + x2) // 2
                midpoint_y = (y1 + y2) // 2

                # Convert midpoint coordinates from pixels to centimeters
                midpoint_x_cm = (origin_y - midpoint_y) * conversion_factor
                midpoint_y_cm = -(midpoint_x - origin_x) * conversion_factor  # Invert the sign of y-coordinate

                # Draw line from midpoint to origin (adjusted)
                cv2.line(img, (midpoint_x, midpoint_y), (origin_x, origin_y), (255, 255, 0), 2)

                # Print midpoint coordinates (adjusted)
                print("Midpoint Coordinates (cm):", (midpoint_x_cm, midpoint_y_cm))

                # Calculate distance between left and right vertical lines
                distance = (x2 - x1) * conversion_factor
                print("Distance between lines (cm):", distance)

    # Draw axes (adjusted for the new origin)
    cv2.line(img, (origin_x, 0), (origin_x, height), (0, 255, 0), 2)  # Y-axis (Green)
    cv2.line(img, (0, origin_y), (width, origin_y), (0, 0, 255), 2)  # X-axis (Red)

    # Label axes
    cv2.putText(img, 'X', (origin_x + 10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
    cv2.putText(img, 'Y', (10, origin_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Display the image
    cv2.imshow('Webcam', img)

    # Exit condition
    if cv2.waitKey(1) == ord('q'):
        break

# Cleanup
cap.release()
cv2.destroyAllWindows()
